{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadisk1/ixk5174/project_repo/Telos-test\n",
      "test_output/pacbio_ENCFF370NFS_isoquant/features/pacbio_ENCFF370NFS_isoquant_tss_labeled.tsv\n",
      "df_cov.shape: (29293, 14)\n",
      "df_label.shape: (29293, 2)\n",
      "After merging df_tss with df_cov, df.shape: (29293, 95)\n",
      "After merging df_label with df, df.shape: (29293, 6)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_transcript'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/datadisk1/shared/tools/anaconda/install-2024.08/envs/irtesam-berth/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'label_transcript'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAfter merging df_label with df, df.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# print(df.head(30))\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# comparison between tss and transcript labels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m matched_labels = df[df[\u001b[33m\"\u001b[39m\u001b[33mlabel_tss\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel_transcript\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmatched_labels.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatched_labels.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m mismatch_labels = df[df[\u001b[33m\"\u001b[39m\u001b[33mlabel_tss\u001b[39m\u001b[33m\"\u001b[39m] != df[\u001b[33m\"\u001b[39m\u001b[33mlabel_transcript\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/datadisk1/shared/tools/anaconda/install-2024.08/envs/irtesam-berth/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/datadisk1/shared/tools/anaconda/install-2024.08/envs/irtesam-berth/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'label_transcript'"
     ]
    }
   ],
   "source": [
    "from extract_features import extract_features\n",
    "from config import load_config\n",
    "import pysam\n",
    "import pandas as pd\n",
    "from ml_utils import load_tmap_labels\n",
    "import os\n",
    "\n",
    "os.chdir(\"/datadisk1/ixk5174/project_repo/Telos-test/\")\n",
    "print(os.getcwd())\n",
    "\n",
    "cfg = load_config(\"project_config/pacbio_ENCFF370NFS_isoquant_config.pkl\")\n",
    "# bam = pysam.AlignmentFile(\"../\" + cfg.bam_file, \"rb\")  # <-- adjust path if needed\n",
    "print(cfg.tss_labeled_file)\n",
    "df_tss = pd.read_csv(cfg.tss_labeled_file, dtype={\"chrom\": str})\n",
    "df_tes = pd.read_csv(cfg.tes_labeled_file, dtype={\"chrom\": str})\n",
    "\n",
    "df_cov = pd.read_csv(cfg.cov_file, sep=\"\\t\")\n",
    "print(f\"df_cov.shape: {df_cov.shape}\")\n",
    "df_label = load_tmap_labels(cfg.tmap_file)\n",
    "print(f\"df_label.shape: {df_label.shape}\")\n",
    "\n",
    "# print()\n",
    "\n",
    "df = df_cov.merge(df_tss, left_on=[\"tss_chrom\", \"tss_pos\"], right_on=[\"chrom\", \"position\"], how=\"inner\")\n",
    "print(f\"After merging df_tss with df_cov, df.shape: {df.shape}\")\n",
    "\n",
    "df = df[[\"transcript_id\", \"chrom\", \"position\", \"label\", \"coverage\"]]\n",
    "# df = df.merge(df_tes, left_on=[\"tes_chrom\", \"tes_pos\"], right_on=[\"chrom\", \"position\"], how=\"inner\", suffixes=(\"_tss\", \"_tes\"))\n",
    "# print(f\"After merging df_tes with df, df.shape: {df.shape}\")\n",
    "df = df.merge(df_label, left_on=[\"transcript_id\"], right_on=[\"transcript_id\"], how=\"inner\", suffixes=(\"_tss\", \"_tr\"))\n",
    "\n",
    "print(f\"After merging df_label with df, df.shape: {df.shape}\")\n",
    "\n",
    "# print(df.head(30))\n",
    "\n",
    "\n",
    "# comparison between tss and transcript labels\n",
    "matched_labels = df[df[\"label_tss\"] == df[\"label_tr\"]]\n",
    "print(f\"matched_labels.shape: {matched_labels.shape}\")\n",
    "mismatch_labels = df[df[\"label_tss\"] != df[\"label_tr\"]]\n",
    "print(f\"mismatch_labels.shape: {mismatch_labels.shape}\")\n",
    "\n",
    "# sort by coverage\n",
    "sorted_df = df.sort_values(by=\"coverage\", ascending=False)\n",
    "# change print to display all columns without line breaks\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "print(sorted_df.head(100))\n",
    " \n",
    "# generate precision and recall for different coverage bins like a pr curve\n",
    "precisions = []\n",
    "recalls = []\n",
    "n_total = len(sorted_df)\n",
    "n_positive = sorted_df['label_tss'].sum()\n",
    "\n",
    "for k in range(1, n_total + 1, 100):\n",
    "    # Keep top k highest coverage points\n",
    "    subset = sorted_df.iloc[:k]\n",
    "    n_kept = len(subset)\n",
    "    n_tp = subset['label_tss'].sum()  # true positives in kept subset\n",
    "    n_fp = n_kept - n_tp  # false positives in kept subset\n",
    "    \n",
    "    # Precision = TP / (TP + FP)\n",
    "    precision = n_tp / n_kept \n",
    "    # Recall = TP / (total positive)  \n",
    "    recall = n_tp / n_positive \n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "# Create dataframe with PR curve data\n",
    "pr_df = pd.DataFrame({\n",
    "    'precision': precisions,\n",
    "    'recall': recalls\n",
    "})\n",
    "print(f\"PR curve data shape: {pr_df.shape}\")\n",
    "\n",
    "print(pr_df.sort_values(by=\"recall\", ascending=False).head(30))\n",
    "\n",
    "# generate precision and recall for different coverage bins like a pr curve for transcript labels\n",
    "precisions = []\n",
    "recalls = []\n",
    "n_total = len(sorted_df)\n",
    "n_positive = sorted_df['label_tr'].sum()\n",
    "\n",
    "for k in range(1, n_total + 1, 100):\n",
    "    subset = sorted_df.iloc[:k]\n",
    "    n_kept = len(subset)\n",
    "    n_tp = subset['label_tr'].sum()\n",
    "    n_fp = n_kept - n_tp\n",
    "    \n",
    "    precision = n_tp / n_kept\n",
    "    recall = n_tp / n_positive\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    \n",
    "\n",
    "pr_df_transcript = pd.DataFrame({\n",
    "    'precision': precisions,\n",
    "    'recall': recalls\n",
    "})\n",
    "\n",
    "print(pr_df_transcript.head(30))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b62c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datadisk1/ixk5174/project_repo/Telos-test\n",
      "Accuracy of model: 0.8783683821198351\n",
      "Inc_count: 1151\n"
     ]
    }
   ],
   "source": [
    "from ml_utils import load_tmap_labels\n",
    "from config import load_config\n",
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "from ml_utils import stratified_split\n",
    "\n",
    "os.chdir(\"/datadisk1/ixk5174/project_repo/Telos-test/\")\n",
    "print(os.getcwd())\n",
    "\n",
    "project_config = load_config(\"project_config/cDNA-NA12878_stringtie_config.pkl\")\n",
    "pred_df = pd.read_csv(f\"{project_config.predictions_output_dir}/randomforest_stage2_predictions_train.csv\", sep = \"\\t\")\n",
    "\n",
    "# find accuracy of model\n",
    "acc = 0\n",
    "inc_count = 0\n",
    "# pred_df['pred_label'] = pred_df['pred_label'].astype(int)\n",
    "for i in range(len(pred_df)):\n",
    "    if pred_df.iloc[i]['pred_label'] == pred_df.iloc[i]['label']:\n",
    "        acc += 1\n",
    "    else:\n",
    "        # print(f\"pred_df.iloc[i]:  {pred_df.iloc[i]}\")\n",
    "        inc_count += 1\n",
    "print(f\"Accuracy of model: {acc/len(pred_df)}\")\n",
    "print(f\"Inc_count: {inc_count}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "irtesam-berth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
